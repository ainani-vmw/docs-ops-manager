---
title: Preparing to deploy Tanzu Operations Manager on GCP
owner: Ops Manager
iaas: GCP
---

You must follow these steps before you install <%= vars.ops_manager_first %> on Google Cloud Platform (GCP).

## <a id='prerequisites'></a> Prerequisites

Before you prepare your <%= vars.ops_manager %> installation, do the following tasks depending on the
  runtime you intend to deploy:

- If you are deploying <%= vars.app_runtime_first %>, see [<%= vars.ops_manager %> on GCP Requirements](../install/gcp.html).

- If you are deploying Enterprise <%= vars.k8s_runtime_first %>, see [GCP Prerequisites and
Resource Requirements](https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid-Integrated-Edition/1.16/tkgi/GUID-gcp-requirements.html).

## <a id='config-components'></a> Configuration and components

This section outlines high-level infrastructure options for <%= vars.ops_manager %> on GCP. A <%= vars.ops_manager %> deployment includes <%= vars.ops_manager %> and your chosen runtime. For example, both <%= vars.ops_manager %> with <%= vars.app_runtime_abbr %>
and <%= vars.ops_manager %> with <%= vars.k8s_runtime_abbr %> are <%= vars.ops_manager %> deployments. For more information, review the deployment
options and recommendations in [Reference Architecture for <%= vars.ops_manager %> on GCP](../refarch/gcp/gcp_ref_arch.html).

You can deploy <%= vars.ops_manager %> using one of two main configurations on a GCP virtual private cloud (VPC):

- A _single-project_ configuration that gives <%= vars.ops_manager %> full access to VPC resources
- A _shared VPC_ configuration in which <%= vars.ops_manager %> shares VPC resources

See [Shared vs Single-Project VPCs](../refarch/gcp/gcp_ref_arch.html#shared-vs-single) in _Reference Architecture for <%= vars.ops_manager %> on GCP_ for a full discussion and recommendations.

When deploying <%= vars.ops_manager %> on GCP, <%= vars.company_name %> recommends using the following GCP components:

- [Google Cloud SQL](https://cloud.google.com/sql/docs/) for external database services
- [NAT Gateway Instances](https://cloud.google.com/solutions/connecting-securely#natgateway) to limit the number of VMs with public IP addresses
- [Google Cloud Storage](https://cloud.google.com/storage/) for external file storage

## <a id='iam_account'></a> Step 1: Set up IAM service accounts

<%= vars.ops_manager %> uses IAM service accounts to access GCP resources.

**For a single-project installation**: Complete the following steps to create a service account for <%= vars.ops_manager %>.

**For a shared-VPC installation**: Complete the following steps twice, to create a host account and service account for <%= vars.ops_manager %>.

1. From the GCP console, click **IAM & Admin**, then **Service accounts**.

1. Click **Create Service Account**:

- **Service account name**: Enter a name. For example, `bosh`.
- **Role**: Use the drop-down menu, select the following roles:
        ***Service Accounts > Service Account User**
        * **Service Accounts > Service Account Token Creator**
        ***Compute Engine > Compute Instance Admin (v1)**
        * **Compute Engine > Compute Network Admin**
        ***Compute Engine > Compute Storage Admin**
        * **Storage > Storage Admin**

        <p> You must scroll down in the pop-up windows to select all required roles.<br><br>
        The <strong>Service Account User</strong> role is required only if you plan to use <strong>The <%= vars.ops_manager %> VM Service Account</strong> to deploy <%= vars.ops_manager %>. For more information about <strong>The <%= vars.ops_manager %> VM Service Account</strong>, see <a href="config-manual.html#gcp-config">Step 2: Google Cloud Platform Config</a> in <em>Configuring BOSH Director on GCP</em>.</p>

- **Service account ID**: The text box automatically generates a unique ID based on the username.
- **Furnish a new private key**: Select this checkbox and JSON as the **Key type**.

      ![alt-text=""](../common/images/gcp/iam_account_2.png)

1. Click **Create**. Your browser automatically downloads a JSON file with a private key for this account. Save this file in a secure location.

<p> You can use this service account to configure file storage for <%= vars.app_runtime_abbr %>.
For more information, see <a href="https://docs.vmware.com/en/VMware-Tanzu-Application-Service/3.0/tas-for-vms/pas-file-storage.html#gcp">GCP</a> in <em>Configuring File Storage for <%= vars.app_runtime_abbr %></em>.</p>

## <a id='enable_compute_resource_api'></a> Step 2: Enable Google Cloud APIs

<%= vars.ops_manager %> manages GCP resources using the Google Compute Engine and Cloud Resource Manager APIs. To enable these APIs:

1. Log in to the Google Developers Console at [https://console.developers.google.com](https://console.developers.google.com).

1. In the console, go to the GCP projects where you want to install <%= vars.ops_manager %>.

- For a single-project installation, complete the following steps for the <%= vars.ops_manager %> project.
- For a shared-VPC installation, complete the following steps for both host and service projects, to enable them to access the Google Cloud API.

1. Click **API Manager > Library**.

1. Under **Google Cloud APIs**, click **Compute Engine API**.

1. On the **Google Compute Engine API** pane, click **Enable**.

1. In the search text box, enter `Google Cloud Resource Manager API`.

1. On the **Google Cloud Resource Manager API** pane, click **Enable**.

1. To verify that the APIs have been enabled, complete the following steps:
    1. Log in to GCP using the IAM service account you created in [Set up IAM Service Accounts](#iam_account):
     <pre class="terminal">
     $ gcloud auth activate-service-account --key-file JSON_KEY_FILENAME
     </pre>

    1. List your projects:
      <pre class="terminal">
      $ gcloud projects list
      PROJECT_ID              NAME                      PROJECT_NUMBER
      my-host-project-id      my-host-project-name      ##############
      my-service-project-id   my-service-project-name   ##############
      </pre>
      This command lists the projects where you enabled Google Cloud APIs.

## <a id='create_network'></a> Step 3: Create a GCP network with subnets

1. Log in to the [GCP console](https://console.cloud.google.com/).

1. Go to the GCP project where you want to install <%= vars.ops_manager %>. For a shared VPC installation,
go to the host project.

1. Click **VPC network** > **CREATE VPC NETWORK**.

    ![alt-text="On the GCP console, the VPC Network page has two sections: VPC Networks and External IP Addresses."](../common/images/gcp/gcp-vpc-networks.png)

1. In the **Name** text box, enter a name of your choice for the VPC network. This name helps you identify resources for this deployment in the GCP console. Network names must be lowercase. For example, `pcf-virt-net`.<br>

    1. Under **Subnets**, complete the form as follows to create an infrastructure subnet for <%= vars.ops_manager %> and NAT instances:

        <table class=“table”>
        <thead><tr>
          <th style="width:22%">Name</th>
          <td><code>pcf-infrastructure-subnet-GCP-REGION</code><br>
          Example: <code>pcf-infrastructure-subnet-us-west1</code></td>
        </tr></thead>
        <tr>
          <th>Region</th>
          <td>A region that supports three availability zones. For help selecting the correct region for your deployment, see the <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones">Google documentation about regions and zones</a>.</td>
        </tr>
        <tr>
        <th>IP address range</th>
        <td>A CIDR ending in <code>/26</code><br>
        Example: <code>192.168.101.0/26</code></td>
        </tr>
      </table>

        See the following image for an example:

        ![alt-text="The New subnet dialog box includes these sections: Name, Region, IP address range, Private Google access, and Flow logs."](../common/images/gcp/gcp-vpc-subnet.png)

        <p> For deployments that do not use external IP addresses, enable <strong>Private Google access</strong> to allow your runtime to make API calls to Google services.</p>

    2. Click **Add subnet** to add a second subnet for the BOSH Director and components specific to your runtime. Complete the form as follows:

      <table class=“table”>
      <thead>
        <tr>
          <th style="width:25%">Name</th>
          <td><code>pcf-RUNTIME-subnet-GCP-REGION</code><br>
          Example: <code>pcf-pas-subnet-us-west1</code></td>
        </tr>
        </thead>
        <tr>
          <th>Region</th>
          <td>The same region you selected for the infrastructure subnet</td>
        </tr>
        <tr>
        <th>IP address range</th>
        <td>A CIDR ending in <code>/22</code><br>
          Example: <code>192.168.16.0/22</code></td>
        </tr>
      </table>

    3. Click **Add subnet** to add a third **Subnet** with the following details:

<table class=“table”>
  <tr>
    <th style="width:25%">Name</th>
    <td><code>pcf-services-subnet-GCP-REGION</code><br>
    Example: <code>pcf-services-subnet-us-west1</code></td>
  </tr>
  <tr>
    <th>Region</th>
    <td>The same region you selected for the previous subnets</td>
  </tr>
  <tr>
  <th>IP address range</th>
  <td>A CIDR in <code>/22</code><br>
      Example: <code>192.168.20.0/22</code></td>
  </tr>
</table>

        See the following image for an example:

        ![alt-text="The VPC networks wizard shows three example subnets."](../common/images/gcp/vpc_subnetworks.png)

1. Under **Dynamic routing mode**, leave **Regional** selected.

1. Click **Create**.

## <a id='create_nat'></a> Step 4: Create NAT instances

Use NAT instances when you want to expose only a minimal number of public IP addresses.

Creating NAT instances permits internet access from cluster VMs.
You might, for example, need this internet access for pulling Docker images or enabling internet access for your workloads.

For more information, see [Reference Architecture for <%= vars.ops_manager %> on GCP](../refarch/gcp/gcp_ref_arch.html#common_network) and the [GCP documentation](https://cloud.google.com/solutions/connecting-securely#natgateway).

1. In the GCP console, with your single project or shared-VPC host project selected, go to **Compute Engine** > **VM instances**.

    ![alt-text=""](../common/images/gcp/gcp-vm-instances.png)

1. Click **CREATE INSTANCE**.

    ![alt-text="The GCP Console Compute Engine page shows the Create Instance button."](../common/images/gcp/gcp-vm-create.png)

2. Complete the following text boxes:

    - **Name**: Enter `pcf-nat-gateway-pri`. <br>
      This is the first, or primary, of three NAT instances you need.
      If you use a single AZ, you need only one NAT instance.
    - **Zone**: Click the first zone from your region.<br>
      Example: For region `us-west1`, click `us-west1-a` zone.
    - **Machine type**: Click `n1-standard-4`.
    - **Boot disk**: Click **Change** and click `Ubuntu 14.04 LTS`.

    ![alt-text="The Create Instance dialog box showing the sections: Name, Zone, Machine Type, and Boot disk."](../common/images/gcp/gcp-primary-nat.png)

3. Expand the additional configuration text boxes by clicking **Management, disks, networking, SSH keys**.

    ![alt-text="The Management, disks, networking, SSH keys drop-down menu."](../common/images/gcp/gcp-nat-dropdown.png)

    1. In the **Startup script** text box under **Automation**, enter the following text:

        ```
        #! /bin/bash
        sudo sysctl -w net.ipv4.ip_forward=1
        sudo sh -c 'echo net.ipv4.ip_forward=1 >> /etc/sysctl.conf'
        sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
        ```

4. Click **Networking** to open additional network configuration text boxes:

    ![alt-text="The page includes the tabs: Management, Disks, Networking, and SSH Keys."](../common/images/gcp/gcp-nat-network.png)

    1. In the **Network tags** text box, add the following: `nat-traverse` and `pcf-nat-instance`.
    2. Click the **Networking** tab and the pencil icon to edit the **Network interface**.
    3. For **Network**, click `pcf-virt-net`. You created this network in [Step 1: Create a GCP Network with Subnets](#create-net).
    4. For **Subnetwork**, click `pcf-infrastructure-subnet-GCP-REGION`.
    5. For **Primary internal IP**, click `Ephemeral (Custom)`. Enter an IP address, for example, `192.168.101.2`, in the **Custom ephemeral IP address** text box. The IP address must meet the following requirements:

        - The IP address must exist in the CIDR range you set for the `pcf-infrastructure-subnet-GCP-REGION` subnet.
        - The IP address must exist in a reserved IP range set later in BOSH Director. The reserved range is typically the first `.1` through `.9` addresses in the CIDR range you set for the `pcf-infrastructure-subnet-GCP-REGION` subnet.
        - The IP address cannot be the same as the Gateway IP address set later in <%= vars.ops_manager %>. The Gateway IP address is typically the first `.1` address in the CIDR range you set for the `pcf-infrastructure-subnet-GCP-REGION` subnet.

    6. For **External IP**, click `Ephemeral`.

        <p> If you select a static external IP address for the NAT instance, then you can use the
        static IP to further secure access to your CloudSQL instances.</p>

    7. Set **IP forwarding** to `On`.
    8. Click **Done**.

5. Click **Create** to finish creating the NAT instance.

6. Repeat steps 2 through 6 to create two additional NAT instances with the names and zones specified in the following table. The rest of the configuration remains the same.

  <table class=“table”>
  <thead>
  <tr>
    <th rowspan="3" width="15%">Instance 2</th>
    <td width="15%"><strong>Name</strong></td>
    <td>
      <code>pcf-nat-gateway-sec</code>
    </td>
  </tr>
  </thead>
  <tr>
    <td><strong>Zone</strong></td>
    <td>
      Select the second zone from your region.<br>
      Example: For region <code>us-west1</code>, select zone <code>us-west1-b</code>.<br>
    </td>
  </tr>
  <tr>
    <td><strong>Internal IP</strong></td>
    <td>
      Select <code>Custom</code> and enter an IP address in the <strong>Internal IP address</strong> text box. Example: <code>192.168.101.3</code>.
      <br><br>As described previously, this address must in the CIDR range you set for the <code>pcf-infrastructure-subnet-GCP-REGION</code> subnet, must exist in a reserved IP range set later in BOSH Director, and cannot be the same as the Gateway IP address set later in <%= vars.ops_manager %>.
    </td>
  </tr>
  <tr>
    <th rowspan="3">Instance 3</th>
    <td><strong>Name</strong></td>
    <td>
      <code>pcf-nat-gateway-ter</code>
    </td>
  </tr>
  <tr>
    <td><strong>Zone</strong></td>
    <td>
      Select the third zone from your region.<br>
      Example: For region <code>us-west1</code>, select zone <code>us-west1-c</code>.
    </td>
  </tr>
  <tr>
    <td><strong>Internal IP</strong></td>
    <td>
      Select <code>Custom</code> and enter an IP address in the <strong>Internal IP address</strong> text box. Example: <code>192.168.101.4</code>.
      <br><br>As previously described, this address must in the CIDR range you set for the <code>pcf-infrastructure-subnet-GCP-REGION</code> subnet, must exist in a reserved IP range set later in BOSH Director, and cannot be the same as the Gateway IP address set later in <%= vars.ops_manager %>.
    </td>
  </tr>
</table>

### <a id='nat-routes'></a> Create routes for NAT instances

1. Go to **VPC Networks** > **Routes**.

    ![alt-text="The Networking menu includes these options: VPC network, Network Services, VPN."](../common/images/gcp/gcp-vpc-routes.png)

1. Click **CREATE ROUTE**.

1. Complete the form as follows:

    - **Name**: `pcf-nat-pri`
    - **Network**: `pcf-virt-net`
    - **Destination IP range**: `0.0.0.0/0`
    - **Priority**: `800`
    - **Instance tags**: `pcf`
    - **Next hop**: `Specify an instance`
    - **Next hop instance**: `pcf-nat-gateway-pri`

1. Click **Create** to finish creating the route.

1. Repeat steps 2 through 4 to create two additional routes with the names and next hop instances specified in the following table. The rest of the configuration remains the same.

  <table class=“table”>
  <tr>
    <th>Route 2</th>
    <td>
      <strong>Name</strong>: <code>pcf-nat-sec</code><br>
      <strong>Next hop instance</strong>: <code>pcf-nat-gateway-sec</code>
    </td>
  </tr>
  <tr>
    <th>Route 3</th>
    <td>
      <strong>Name</strong>: <code>pcf-nat-ter</code><br>
      <strong>Next hop instance</strong>: <code>pcf-nat-gateway-ter</code>
    </td>
  </tr>
</table>

## <a id='firewall_rules'></a> Step 5: Create firewall rules for the network

GCP lets you assign tags to VM instances and create firewall rules that apply to VMs based on their tags. For more information about tags, see [Labeling Resources](https://cloud.google.com/compute/docs/labeling-resources) in the GCP documentation.
This step assigns tags and firewall rules to <%= vars.ops_manager %> components and VMs that handle incoming traffic.

1. With your single project or shared-VPC host project selected, go to the **Networking** > **VPC network** pane and select **Firewall rules**.

1. Apply the firewall rules in the following table:

  <table class=“table”>
  <tr><th colspan="2" style="text-align: center;">Firewall Rules</th></tr>
  <tr>
    <th>Rule 1</th>
    <td>
      This rule allows SSH from public networks.<br><br>
      <strong>Name</strong>: <code>pcf-allow-ssh</code><br>
      <strong>Network</strong>: <code>pcf-virt-net</code><br>
      <strong>Allowed protocols and ports</strong>: <code>tcp:22</code><br>
      <strong>Source filter</strong>: IP ranges<br>
      <strong>Source IP ranges</strong>: <code>0.0.0.0/0</code><br>
      <strong>Target tags</strong>: <code>allow-ssh</code>
    </td>
  </tr>
  <tr>
    <th>Rule 2</th>
    <td>
      This rule allows HTTP from public networks.<br><br>
      <strong>Name</strong>: <code>pcf-allow-http</code><br>
      <strong>Network</strong>: <code>pcf-virt-net</code><br>
      <strong>Allowed protocols and ports</strong>: <code>tcp:80</code><br>
      <strong>Source filter</strong>: IP ranges<br>
      <strong>Source IP ranges</strong>: <code>0.0.0.0/0</code><br>
      <strong>Target tags</strong>: <code>allow-http</code>, <code>router</code>
    </td>
  </tr>
  <tr>
    <th>Rule 3</th>
    <td>
      This rule allows HTTPS from public networks.<br><br>
      <strong>Name</strong>: <code>pcf-allow-https</code><br>
      <strong>Network</strong>: <code>pcf-virt-net</code><br>
      <strong>Allowed protocols and ports</strong>: <code>tcp:443</code><br>
      <strong>Source filter</strong>: IP ranges<br>
      <strong>Source IP ranges</strong>: <code>0.0.0.0/0</code><br>
      <strong>Target tags</strong>: <code>allow-https</code>, <code>router</code>
    </td>
  </tr>
  <tr>
    <th>Rule 4</th>
    <td>
      This rule allows GoRouter health checks.<br><br>
      <strong>Name</strong>: <code>pcf-allow-http-8080</code><br>
      <strong>Network</strong>: <code>pcf-virt-net</code><br>
      <strong>Allowed protocols and ports</strong>: <code>tcp:8080</code><br>
      <strong>Source filter</strong>: IP ranges<br>
      <strong>Source IP Ranges</strong>: <code>0.0.0.0/0</code><br>
      <strong>Target tags</strong>: <code>router</code>
    </td>
  </tr>
  <tr>
    <th>Rule 5</th>
    <td>
      This rule allows communication between BOSH-deployed jobs.<br><br>
      <strong>Name</strong>: <code>pcf-allow-pas-all</code><br>
      <strong>Network</strong>: <code>pcf-virt-net</code><br>
      <strong>Allowed protocols and ports</strong>: <code>tcp;udp;icmp</code><br>
      <strong>Source filter</strong>: Source tags<br>
      <strong>Target tags</strong>: <code>pcf</code>, <code>pcf-opsman</code>, <code>nat-traverse</code><br>
      <strong>Source tags</strong>: <code>pcf</code>, <code>pcf-opsman</code>, <code>nat-traverse</code>
    </td>
  </tr>
  <tr>
    <th>Rule 6 (Optional)</th>
    <td>
      This rule allows access to the TCP router.<br><br>
      <strong>Name</strong>: <code>pcf-allow-cf-tcp</code><br>
      <strong>Network</strong>: <code>pcf-virt-net</code><br>
      <strong>Source filter</strong>: IP ranges<br>
      <strong>Source IP ranges</strong>: <code>0.0.0.0/0</code><br>
      <strong>Allowed protocols and ports</strong>: <code>tcp:1024-65535</code><br>
      <strong>Target tags</strong>: <code>pcf-cf-tcp</code>
    </td>
  </tr>
  <tr>
    <th>Rule 7 (Optional)</th>
    <td>
      This rule allows access to the SSH proxy.<br><br>
      <strong>Name</strong>: <code>pcf-allow-ssh-proxy</code><br>
      <strong>Network</strong>: <code>pcf-virt-net</code><br>
      <strong>Source filter</strong>: IP ranges<br>
      <strong>Source IP ranges</strong>: <code>0.0.0.0/0</code><br>
      <strong>Allowed protocols and ports</strong>: <code>tcp:2222</code><br>
      <strong>Target tags</strong>: <code>pcf-ssh-proxy</code>, <code>diego-brain</code><br>
    </td>
  </tr>
</table>

   <p> If you want your firewall rules to only permit traffic within your private network, modify
   the <strong>Source IP Ranges</strong> from the table accordingly.</p>

1. If you are only using your GCP project to deploy <%= vars.ops_manager %>, then you can delete the following default firewall rules:

    - `default-allow-http`
    - `default-allow-https`
    - `default-allow-icmp`
    - `default-allow-internal`
    - `default-allow-rdp`
    - `default-allow-ssh`

If you are deploying **<%= vars.k8s_runtime_abbr %> only**, continue to [Next steps](#next-steps).

If you are deploying **<%= vars.app_runtime_abbr %> or other runtimes**, proceed to the following step.

## <a id='dbs'></a> Step 6: Create database instance and databases

### <a id='create-dbs-instance'></a> Create database instance

1. For a shared-VPC installation, click the service project in the GCP console. This step and the following steps allocate resources to the service project, not the host project.

1. From the GCP console, click **SQL** and click **CREATE INSTANCE**.

1. Ensure **MySQL** is selected and click **Next**.

1. Under **MySQL**, click **Second Generation** instance type.

1. Click **Configure MySQL** under your choice for instance type: Development, Staging, or Production.

1. Configure the instance as follows:

    - **Instance ID**: `pcf-pas-sql`
    - **Root password**: Set a password for the root user.
    - **Region**: Select the region you specified when creating networks.
    - **Zone**: **Any**.
    - **Configure machine type and storage**:
       - Click **Change** and then select **db-n1-standard-2**.
       - Ensure that **Enable automatic storage increases** is selected. This allows DB storage to grow automatically when space is required.
    - **Enable auto backups and high availability**: Make the following selections:
       - Leave **Automate backups** and **Enable binary logging** selected.
       - Under **High availability**, select the **Create failover replica** checkbox.
    - **Authorize Networks**: Click **Add network** and create a network named `all` that allows traffic from `0.0.0.0/0`.

        <p> If you assigned static IP addresses to your NAT instances, you can instead limit access to the
        database instances by specifying the NAT IP addresses.</p>

1. Click **Create**.

### <a id='create-dbs'></a> Create databases

1. Go to the **Instances** page and select the database instance you just created.

1. Select the **Databases** tab.

1. Click **Create database** to create the following databases:

    - `account`
    - `app_usage_service`
    - `autoscale`
    - `ccdb`
    - `console`
    - `diego`
    - `locket`
    - `networkpolicyserver`
    - `nfsvolume`
    - `notifications`
    - `routing`
    - `silk`
    - `uaa`
    - `credhub`

1. Select the **USERS** tab.

1. Click **Create user account** to create a unique username and password for each database you previously created. For **Host name**, select **Allow any host**. You must create a total of fourteen user accounts.

<p> Ensure that the networkpolicyserver database user has the <code>ALL PRIVILEGES</code> permission.</p>

## <a id='buckets'></a> Step 7: Create storage buckets

1. With your single project or shared-VPC service project selected in the GCP console, click **Storage** > **Browser**.

1. Using **CREATE BUCKET**, create buckets with the following names. For **Default storage class**, click **Multi-Regional**:

    - `PREFIX-pcf-buildpacks`
    - `PREFIX-pcf-droplets`
    - `PREFIX-pcf-packages`
    - `PREFIX-pcf-resources`
    - `PREFIX-pcf-backup`

    Where `PREFIX` is a prefix of your choice, required to make the bucket name unique.

## <a id='loadbalancer'></a> Step 8: Create HTTP load balancer

For load balancing, you can use a global HTTP load balancer or an internal, regional load balancer with a private IP address.

Single project, standalone installations typically use a global HTTP load balancer. For more information, see [Create HTTP Load Balancer](#http_loadbalancer) on how to set this up.

Shared-VPC installation typically use an internal TCP/UDP load balancer to minimize public IP addresses. For more information, see [Create Internal Load Balancer](#internal_loadbalancer) on how to set this up.

### <a id='internal_loadbalancer'></a> Create internal load balancer

To create an internal load balancer for <%= vars.ops_manager %> on GCP, do the following.

1. Create an internal-facing TCP/UDP load balancer for each region of your <%= vars.ops_manager %> deployment.

    <p> GCP Internal Load Balancer (iLB) is a regional product. Within the same VPC/network, client VMs in a different region from the iLB cannot access the iLB. For more information, see the <a href="https://cloud.google.com/load-balancing/docs/internal/setting-up-internal#global_routing_issue">GCP documentation</a>.</p>

1. Assign private IP addresses to the load balancers.

1. After you have deployed <%= vars.ops_manager %>, follow instructions in [Create or Update a VM Extension](../install/custom-vm-extensions.html#create-vm-extension) to add a custom VM extension that applies internal load balancing to all VMs deployed by BOSH.

    - For example, the following manifest code adds a VM extension `backend-pool` to <%= vars.ops_manager %> VMs:

        ```
        vm_extensions:
        - name: backend-pool
          cloud_properties:
            ephemeral_external_ip: true
            backend_service:
              name: name-of-backend-service
              scheme: INTERNAL
        ```

### <a id='http_loadbalancer'></a> Create HTTP load balancer

To create a global HTTP load balancer for <%= vars.ops_manager %> on GCP:

1. [Create Instance Group](#create-instance-group).
1. [Create Health Check](#create-health-check).
1. [Configure Back End](#config-backend).
1. [Configure Front End](#config-frontend).

#### <a id='create-instance-group'></a> Create instance group

1. Go to **Compute Engine** > **Instance groups**.

1. Click **CREATE INSTANCE GROUP**.

1. Complete the form as follows:

- For **Name**, enter `pcf-http-lb`
- For **Location**, click **Single-zone**.
- For **Zone**, click the first zone from your region.<br>
    Example: For region `us-west1`, click zone `us-west1-a`.
- Under **Group type**, click **Unmanaged instance group**.
- For **Network**, click `pcf-virt-net`.
- For **Subnetwork**, click the `pcf-pas-subnet-my-gcp-region` subnet that you created previously.
- Click **Create**.

1. Create a second instance group with the following details:

- **Name**: `pcf-http-lb`
- **Location**: **Single-zone**
- **Zone**: Click the second zone from your region.<br>
    Example: For region `us-west1`, click zone `us-west1-b`.
- **Group type**: Click **Unmanaged instance group**.
- **Network**: Click `pcf-virt-net`.
- **Subnetwork**: Click the `pcf-pas-subnet-my-gcp-region` subnet that you created previously.

1. Create a third instance group with the following details:

- **Name**: `pcf-http-lb`
- **Location**: **Single-zone**
- **Zone**: Click the third zone from your region.<br>
    Example: For region `us-west1`, click zone `us-west1-c`.
- **Group type**: Click **Unmanaged instance group**.
- **Network**: Click `pcf-virt-net`.
- **Subnetwork**: Click the `pcf-pas-subnet-my-gcp-region` subnet that you created previously.

#### <a id='create-health-check'></a> Create health check

1. Go to **Compute Engine** > **Health checks**.

1. Click **CREATE HEALTH CHECK**.

1. Complete the form as follows:

- **Name**: `pcf-cf-public`
- **Port**: `8080`
- **Request path**: `/health`
- **Check interval**: `30`
- **Timeout**: `5`
- **Healthy threshold**: `10`
- **Unhealthy threshold**: `2`

1. Click **Create**.

#### <a id='config-backend'></a> Configure back end

1. Go to **Network services** > **Load balancing**.

1. Click **CREATE LOAD BALANCER**.

1. Under **HTTP(S) Load Balancing**, click **Start configuration**.

1. For the **Name**, enter `pcf-global-pcf`.

1. Select **Backend configuration**
1. From the drop-down menu, click **Backend services** > **Create a backend service**.
1. Complete the form as follows:
    ***Name**: `pcf-http-lb-backend`.
    - **Protocol**: `HTTP`.
    ***Named port**: `http`.
    - **Timeout**: `10 seconds`.
    *Under **Backends** > **New backend**, click the **Instance group** that corresponds to the first zone of the multi-zone instance group you created. For example: `pcf-http-lb (us-west1-a)`. Click **Done**.
    - Click **Add backend**, click the **Instance group** that corresponds to the second zone of the multi-zone instance group you created. For example: `pcf-http-lb (us-west1-b)`. Click **Done**.
    *Click **Add backend**, click the **Instance group** that corresponds to the third zone of the multi-zone instance group you created. For example: `pcf-http-lb (us-west1-c)`. Click **Done**.
    - **Health check**: Click the `pcf-cf-public` health check that you created.
    - **Cloud CDN**: Ensure Cloud CDN is deactivated.

    1. From the drop-down menu, click **Backend services** > **Create a backend service**.
    1. Complete the form as follows:

        - **Name**: `pcf-http-lb-backend`.
        - **Protocol**: `HTTP`.
        - **Named port**: `http`.
        - **Timeout**: `10 seconds`.
        - Under **Backends** > **New backend**, click the **Instance group** that corresponds to the first zone of the multi-zone instance group you created. For example: `pcf-http-lb (us-west1-a)`. Click **Done**.
        - Click **Add backend**, click the **Instance group** that corresponds to the second zone of the multi-zone instance group you created. For example: `pcf-http-lb (us-west1-b)`. Click **Done**.
        - Click **Add backend**, click the **Instance group** that corresponds to the third zone of the multi-zone instance group you created. For example: `pcf-http-lb (us-west1-c)`. Click **Done**.
        - **Health check**: Click the `pcf-cf-public` health check that you created.
        - **Cloud CDN**: Make sure Cloud CDN is inactive.

1. Click **Create**.

#### <a id='config-frontend'></a> Configure front end

1. Click **Host and path rules** to populate the default text boxes and a green check mark.

1. Click **Frontend configuration**, and add the following:
   - **Name**: `pcf-cf-lb-http`
   - **Protocol**: `HTTP`
   - **IP**: Perform the following steps:
       1. Click **Create IP address**.
       1. Enter a **Name** for the new static IP address and an optional description. For example, `pcf-global-pcf`.
       1. Click **Reserve**.
   - **Port**: `80`

1. Click **Add Frontend IP and port** and add the following:

    <p> Skip this step if you do not have either a self-signed or trusted SSL certificate.</p>

       When you configure the tile for your chosen runtime, you are given the opportunity to create a new self-signed certificate.
       Upon creating a certificate, you can complete the <strong>Add Frontend IP and port</strong> section.</p>

    - **Name**: `pcf-cf-lb-https`
    - **Protocol**: `HTTPS`
    - **IP address**: Click the `pcf-global-pcf` address you create for the previous **Frontend IP and Port**.
    - **Port**: `443`
    - Select **Create a new certificate**. The **Create a New Certificate** dialog is displayed.
    - In the **Name** text box, enter a name for the certificate.

      ![alt-text=""](../common/images/gcp/lb_frontend_cert.png)

    - In the **Public key certificate** text box, copy in the contents of your public certificate, or upload your certificate as a .pem file.
    If the certificate is runtime-generated, copy and paste the generated contents from the runtime's Certificate text box into the BOSH Director **Public key certificate** text box.
    - In the **Certificate chain** text box, enter or upload your certificate chain in the .pem format.
    If you are using a self-signed certificate, such as a <%= vars.app_runtime_abbr %> or <%= vars.k8s_runtime_abbr %>-generated certificate, do not enter a value in the **Certificate Chain** text box.
    - In the **Private key** text box, copy in the contents or upload the .pem file of the private key for the certificate.
    If the certificate is runtime-generated, copy and paste the generated contents from the runtime's Private Key text box into the BOSH Director **Private key** text box.

1. Review the completed frontend configuration.

2. Click **Review and finalize** to verify your configuration.

3. Click **Create**.

## <a id='tcp_websockets_lb'></a> Step 9: Create TCP WebSockets load balancer

The load balancer for tailing logs with WebSockets for <%= vars.ops_manager %> on GCP operates on TCP port `443`.

1. From the GCP console, click **Network services > Load balancing > Create load balancer**.

1. Under **TCP Load Balancing**, click **Start configuration**.

    ![alt-text="The Create a load balancer page has three sections: HTTP(S) Load Balancing, TCP Load Balancing, and UDP Load Balancing."](../common/images/gcp/create_new_lb.png)

1. On the **Create a load balancer** configuration UI, make the following selections:

    - Under **Internet facing or internal only**, click **From Internet to my VMs**.
    - Under **Multiple regions or single region**, click **Single region only**.
    - Under **Connection termination**, click **No (TCP)**.

      ![alt-text=""](../common/images/gcp/lb_connection_termination.png)

1. Click **Continue**.

2. In the **New TCP load balancer** window, enter `pcf-wss-logs` in the **Name** text box.

3. Click **Backend configuration** to configure the **Backend service**:

    ![alt-text=""](../common/images/gcp/tcp_websockets_backend.png)

    - **Region**: Click the region you used to create the network in [Create a GCP Network with Subnets](#create_network).
    - From the **Health check** drop-down menu, create a health check with the following details:
        - **Name**: `pcf-gorouter`
        - **Port**: `8080`
        - **Request path**: `/health`
        - **Check interval**: `30`
        - **Timeout**: `5`
        - **Healthy threshold**: `10`
        - **Unhealthy threshold**: `2`
    The **Backend configuration** section shows a green check mark.

1. Click **Frontend configuration** to open its configuration window and complete the textb boxes:
    - **Protocol**: `TCP`
    - **IP**: Perform the following steps:
        1. Click **Create IP address**.
        2. For name **Name** for the new static IP address and an optional description. For example, `pcf-gorouter-wss`.
        3. Click **Reserve**.
    - **Port**: `443`

2. Click **Review and finalize** to verify your configuration.

3. Click **Create**.

## <a id='ssh_lb'></a> Step 10: Create SSH proxy load balancer

1. From the GCP console, click **Network services > Load balancing > Create load balancer**.

1. Under **TCP Load Balancing**, click **Start configuration**.

1. Under **Internet facing or internal only**, click **From Internet to my VMs**.

1. Under **Connection termination**, click **No (TCP)**.

    ![alt-text=""](../common/images/gcp/lb_connection_termination.png)

1. Click **Continue**.

2. In the **New TCP load balancer** window, enter `pcf-ssh-proxy` in the **Name** text box.

3. Click **Backend configuration**, and enter the following values:

    - **Region**: Click the region you used to create the network in [Create a GCP Network with Subnet](#create_network).
    - **Backup pool**: `None`
    - **Failover ratio**: `10%`
    - **Health check**: `No health check`

    ![alt-text=""](../common/images/gcp/ssl_lb_backend_config_complete.png)

1. Click **Frontend configuration**, and add the following:

    - **Protocol**: `TCP`
    - **IP**: Perform the following steps:
        1. Click **Create IP address**.
        2. Enter a **Name** for the new static IP address and an optional description. For example, `pcf-ssh-proxy`.
        3. Click **Reserve**.
    - **Port**: `2222`

2. (Optional) Review and finalize your load balancer.

3. Click **Create**.

## <a id='tcp_lb'></a> Step 11: Create load balancer for TCP router

<p> This step is optional and only required if you enable TCP routing in your deployment.</p>

To create a load balancer for TCP routing in GCP:

1. From the GCP console, click **Network services > Load balancing > Create load balancer**.

1. Under **TCP Load Balancing**, click **Start configuration**.

1. Under **Connection termination**, click **No (TCP)** and click **Continue**.

1. On the **New TCP load balancer** pane, enter a unique name for the load balancer in the **Name** text box. For example, `pcf-cf-tcp-lb`.

1. Click **Backend configuration**, and enter the following values:

    - **Region**: Click the region you used to create the network in [Create a GCP Network with Subnet](#create_network).
    - From the **Health check** drop-down menu, create a health check with the following details:
        - **Name**: `pcf-tcp-lb`
        - **Port**: `80`
        - **Request path**: `/health`
        - **Check interval**: `30`
        - **Timeout**: `5`
        - **Healthy threshold**: `10`
        - **Unhealthy threshold**: `2`
        - Click **Save and continue**.

          ![alt-text=""](../common/images/gcp/tcp_lb_backend.png)

1. Click **Frontend configuration**, and add the front end IP and port entry as follows:

    - **Protocol**: `TCP`
    - **IP**: Perform the following steps:
        1. Click **Create IP address**.
        2. Enter a **Name** for the new static IP address and an optional description. For example, `pcf-cf-tcp-lb`.
        3. Click **Reserve**.
    - **Port**: `1024-65535`

      ![alt-text=""](../common/images/gcp/tcp_lb_frontend.png)

1. Click **Review and finalize** to verify your configuration.

2. Click **Create**.

## <a id='cname'></a> Step 12: Add DNS records for your load balancers

In this step, you redirect queries for your domain to the IP addresses of your load balancers.

1. Locate the static IP addresses of the load balancers you created in [Preparing to deploy <%= vars.ops_manager %> on GCP](prepare-env-manual.html):

    - An HTTP(S) load balancer named `pcf-global-pcf`
    - A TCP load balancer for WebSockets named `pcf-wss-logs`
    - A TCP load balancer named `pcf-ssh-proxy`
    - A TCP load balancer named `pcf-cf-tcp-lb`

    <p> You can locate the static IP address of each load balancer by clicking its name
    under <strong>Network services > Load balancing</strong> in the GCP console.</p>

1. Log in to the DNS registrar that hosts your domain. Examples of DNS registrars include Network Solutions, GoDaddy, and Register.com.

1. Create **A records** with your DNS registrar that map domain names to the public static IP addresses of the load balancers located previously:

    <table class=“table”>
    <thead>
    <tr>
    <th>Create and map this record...</th><th>To the IP of this load balancer</th><th>Required</th>
    </thead>
    </tr>
    <tr>
      <td><code>\*.sys.MY-DOMAIN</code><br>
      Example: <code>\*.sys.example.com</code></td>
      <td><code>pcf-global-pcf</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code>\*.apps.MY-DOMAIN</code><br>
      Example: <code>\*.apps.example.com</code></td>
      <td><code>pcf-global-pcf</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code>doppler.sys.MY-DOMAIN</code>
      <br>
      Example: <code>doppler.sys.example.com</code></td>
      <td><code>pcf-wss-logs</code></td>
      <td>Yes</td>
    </tr>
          <tr>
      <td><code>loggregator.sys.MY-DOMAIN</code><br>
      Example: <code>loggregator.sys.example.com</code></td>
      <td><code>pcf-wss-logs</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code>ssh.sys.MY-DOMAIN</code>
      <br>
      Example: <code>ssh.sys.example.com</code></td>
      <td><code>pcf-ssh-proxy</code></td>
      <td>Yes, to allow SSH access to apps</td>
    </tr>
    <tr>
      <td><code>tcp.MY-DOMAIN</code>
      <br>
      Example: <code>tcp.example.com</code></td>
      <td><code>pcf-cf-tcp-lb</code></td>
      <td>No, only set up if you have enabled the TCP routing feature</td>
    </tr>
  </table>

1. Save your changes within the web interface of your DNS registrar.

1. Run the following `dig` command to confirm that you created your A record successfully:

    ```
    dig SUBDOMAIN.EXAMPLE-URL.com
    ```

    Where `SUBDOMAIN.EXAMPLE-URL` is the subdomain for your load balancer.

    You see the A record that you just created:

    <pre class="terminal">
    ;; ANSWER SECTION:
    xyz.EXAMPLE.COM.      1767    IN  A 203.0.113.1
    </pre>

## <a id='next-steps'></a> Next steps

(Optional) To prepare for deploying either a <%= vars.app_runtime_abbr %> or <%= vars.k8s_runtime_abbr %> tile on GCP, you can download the
required runtime tile in advance:

- To download <%= vars.app_runtime_abbr %>, log in to [VMware Tanzu Network](https://network.tanzu.vmware.com/products/elastic-runtime), select your desired release version, and download **<%= vars.app_runtime_full %>**.
- To download <%= vars.k8s_runtime_abbr %>, log in to [VMware Tanzu Network](https://network.tanzu.vmware.com/products/pivotal-container-service), select your desired release version, and download **<%= vars.k8s_runtime_full %>**.

After initiating the tile download, proceed to the next step, [Deploying <%= vars.ops_manager %> on GCP](deploy-manual.html).
